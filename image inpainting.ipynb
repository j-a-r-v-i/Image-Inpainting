{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqZQdGoiN-Jl"
      },
      "source": [
        "from __future__ import print_function\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
        "\n",
        "import numpy as np\n",
        "from models.unet import UNet\n",
        "from models.skip import skip\n",
        "import torch\n",
        "import torch.optim\n",
        "\n",
        "from utils.inpainting_utils import *\n",
        "\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.backends.cudnn.benchmark =True\n",
        "dtype = torch.cuda.FloatTensor\n",
        "\n",
        "PLOT = True\n",
        "imsize = -1\n",
        "dim_div_by = 64"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUO7hM5fM6i9"
      },
      "source": [
        "## Fig 7 (top)\n",
        "#for irregluar holes\n",
        "img_path  = '/Ajanta 1 Unrestored.jpg'\n",
        "NET_TYPE = 'UNET' \n",
        "\n",
        "\n",
        "# Another text inpainting example(for text and scrathes)\n",
        "# img_path  = 'data/inpainting/peppers.png'\n",
        "#NET_TYPE = 'skip'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CKzAgU5EeZA"
      },
      "source": [
        "# For creating mask of image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEA5i3j1N9CB"
      },
      "source": [
        "import cv2 as cv\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c23l9y70DntD"
      },
      "source": [
        "img = cv.imread('/content/Ajanta 1 Unrestored.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV92YWHhDrHh"
      },
      "source": [
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMMB3hF0Dt-B"
      },
      "source": [
        "gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
        "ret, thresh = cv.threshold(gray,0,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN1OASU7DxFA"
      },
      "source": [
        "cv.imwrite('mask.png',thresh) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-Q8mYx8EGrp"
      },
      "source": [
        "mask_path = '/content/mask.png'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KPQQYocEmMZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12D99s9ZMV4h"
      },
      "source": [
        "# Load mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ULyPYm7D10Q"
      },
      "source": [
        "img_pil, img_np = get_image(img_path, imsize)\n",
        "img_mask_pil, img_mask_np = get_image(mask_path, imsize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru5dlLYrMcQr"
      },
      "source": [
        "## center crop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti41hyZAD4gQ"
      },
      "source": [
        "img_mask_pil = crop_image(img_mask_pil, dim_div_by)\n",
        "img_pil      = crop_image(img_pil,      dim_div_by)\n",
        "\n",
        "img_np      = pil_to_np(img_pil)\n",
        "img_mask_np = pil_to_np(img_mask_pil)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHbM5F3NMgds"
      },
      "source": [
        "## Visualize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1FN987rD5YZ"
      },
      "source": [
        "img_mask_var = np_to_torch(img_mask_np).type(dtype)\n",
        "\n",
        "plot_image_grid([img_np, img_mask_np, img_mask_np*img_np], 3,11);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN704fiJMn5F"
      },
      "source": [
        "# Setting up everything"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1elozyPD-kZ"
      },
      "source": [
        "pad = 'reflection' # 'zero'\n",
        "OPT_OVER = 'net'\n",
        "OPTIMIZER = 'adam'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQGUFZXUOHOj"
      },
      "source": [
        "t=input(\"Enter 1 for irregular holes and 2 for scratches or text over image\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FrrjnmGIFs7"
      },
      "source": [
        "if t=='1':\n",
        "    \n",
        "    INPUT = 'noise'\n",
        "    input_depth = 32\n",
        "    LR = 0.01 \n",
        "    num_iter = 6001\n",
        "    param_noise = False\n",
        "    show_every = 50\n",
        "    figsize = 5\n",
        "    reg_noise_std = 0.03\n",
        "    \n",
        "    net = skip(input_depth, img_np.shape[0], \n",
        "               num_channels_down = [128] * 5,\n",
        "               num_channels_up =   [128] * 5,\n",
        "               num_channels_skip =    [128] * 5,  \n",
        "               filter_size_up = 3, filter_size_down = 3, \n",
        "               upsample_mode='nearest', filter_skip_size=1,\n",
        "               need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n",
        "    \n",
        "elif t=='2':\n",
        "    \n",
        "    INPUT = 'noise'\n",
        "    input_depth = 6\n",
        "    \n",
        "    num_iter = 3001\n",
        "    show_every = 50\n",
        "    figsize = 8\n",
        "    reg_noise_std = 0.00\n",
        "    param_noise = True\n",
        "    LR = 0.01 \n",
        "    if NET_TYPE == 'UNET':\n",
        "        \n",
        "        net = UNet(num_input_channels=input_depth, num_output_channels=3, \n",
        "                   feature_scale=8, more_layers=1, \n",
        "                   concat_x=False, upsample_mode='deconv', \n",
        "                   pad='zero', norm_layer=torch.nn.InstanceNorm2d, need_sigmoid=True, need_bias=True)\n",
        "        \n",
        "        LR = 0.0001\n",
        "        param_noise = False\n",
        "    else:\n",
        "        assert False\n",
        "else:\n",
        "    assert False\n",
        "\n",
        "net = net.type(dtype)\n",
        "net_input = get_noise(input_depth, INPUT, img_np.shape[1:]).type(dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE7dCpWeNie7"
      },
      "source": [
        "# Main loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl_vz-aKIUCA"
      },
      "source": [
        "i = 0\n",
        "def closure():\n",
        "    \n",
        "    global i\n",
        "    \n",
        "    if param_noise:\n",
        "        for n in [x for x in net.parameters() if len(x.size()) == 4]:\n",
        "            n = n + n.detach().clone().normal_() * n.std() / 50\n",
        "    \n",
        "    net_input = net_input_saved\n",
        "    if reg_noise_std > 0:\n",
        "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
        "        \n",
        "        \n",
        "    out = net(net_input)\n",
        "   \n",
        "    total_loss = mse(out * mask_var, img_var * mask_var)\n",
        "    total_loss.backward()\n",
        "        \n",
        "    print ('Iteration %05d    Loss %f' % (i, total_loss.item()), '\\r', end='')\n",
        "    if  PLOT and i % show_every == 0:\n",
        "        out_np = torch_to_np(out)\n",
        "        plot_image_grid([np.clip(out_np, 0, 1)], factor=figsize, nrow=1)\n",
        "        \n",
        "    i += 1\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "net_input_saved = net_input.detach().clone()\n",
        "noise = net_input.detach().clone()\n",
        "\n",
        "p = get_params(OPT_OVER, net, net_input)\n",
        "optimize(OPTIMIZER, p, closure, LR, num_iter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni9jdZdLI5I4"
      },
      "source": [
        "out_np = torch_to_np(net(net_input))\n",
        "plot_image_grid([out_np], factor=5);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}